{"cells":[{"cell_type":"markdown","metadata":{"id":"dxiNwZer3-E4"},"source":["## 1. Import Data\n","\n","This step brings in important tools that help us work with data, create machine learning models, and make charts."]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":274,"status":"ok","timestamp":1730086030299,"user":{"displayName":"l cn","userId":"00318376737157475686"},"user_tz":420},"id":"utNPPv3_OLbt"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import joblib\n","import os\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import Input, Dense\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.callbacks import EarlyStopping\n","import matplotlib.pyplot as plt\n","from IPython.display import display\n","from google.colab import drive"]},{"cell_type":"markdown","metadata":{"id":"D00w-Wb44Vfn"},"source":["## 2. Load Data\n","\n","Here, we load data from an Excel file, show the first 10 rows to check, and handle any issues if the file doesnâ€™t load properly.\n"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"QTeArVZ1QHr8","colab":{"base_uri":"https://localhost:8080/","height":645},"executionInfo":{"status":"ok","timestamp":1730086056155,"user_tz":420,"elapsed":2840,"user":{"displayName":"l cn","userId":"00318376737157475686"}},"outputId":"deab8d9a-c07d-4790-8eea-a58b83b3cbd9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Data loaded successfully.\n","First 10 rows of the data:\n"]},{"output_type":"display_data","data":{"text/plain":["              Name            Timestamp   Status Description  \\\n","0  Conveyor Belt 4  2023-08-15 00:00:00  Running         NaN   \n","1  Conveyor Belt 4  2023-08-15 00:15:00  Running         NaN   \n","2  Conveyor Belt 4  2023-08-15 00:30:00  Running         NaN   \n","3  Conveyor Belt 4  2023-08-15 00:45:00  Running         NaN   \n","4  Conveyor Belt 4  2023-08-15 01:00:00  Running         NaN   \n","5  Conveyor Belt 4  2023-08-15 01:15:00  Running         NaN   \n","6  Conveyor Belt 4  2023-08-15 01:30:00  Running         NaN   \n","7  Conveyor Belt 4  2023-08-15 01:45:00  Running         NaN   \n","8  Conveyor Belt 4  2023-08-15 02:00:00  Running         NaN   \n","9  Conveyor Belt 4  2023-08-15 02:15:00  Running         NaN   \n","\n","  Vibration Frequency Vibration Amplitude Bearing Temperature  \\\n","0             1490.82                0.04                 NaN   \n","1             1498.37                0.04              77.076   \n","2             1503.22                0.06              77.307   \n","3             1508.11                0.04              77.474   \n","4             1498.13                0.06              77.785   \n","5             1494.89                0.05              77.813   \n","6              1498.2                0.06              77.622   \n","7             1507.17                0.06              78.487   \n","8             1507.43                0.06              78.294   \n","9             1502.35                0.05              78.561   \n","\n","  Motor Temperature Belt Load  Torque Noise Levels Current and Voltage  \\\n","0            96.902      1.36  318.07        55.12               15.79   \n","1            96.975      1.07   295.5        59.68               14.34   \n","2            96.755      1.21  314.38         58.2               15.03   \n","3            97.661      1.29  311.84        56.16               15.43   \n","4            97.471      1.07  317.14        55.39               14.35   \n","5            97.814      1.33  305.58          NaN               15.65   \n","6            97.464      1.18  285.96        59.25               14.91   \n","7            98.139      1.24  298.84        58.93               15.21   \n","8            97.877      1.07  307.51        61.77               14.36   \n","9             98.96      1.17  308.73        62.23               14.87   \n","\n","  Hydraulic Pressure Belt Thickness Roller Condition  \n","0             382.09           1.58               86  \n","1             376.48         1.5795           85.854  \n","2              384.2        1.57925           85.781  \n","3             379.79          1.579           85.708  \n","4             383.95        1.57875           85.635  \n","5             383.02         1.5785           85.562  \n","6             383.54        1.57825           85.489  \n","7             377.37          1.578           85.416  \n","8             377.28        1.57775           85.343  \n","9             377.47         1.5775            85.27  "],"text/html":["\n","  <div id=\"df-1180b0cb-955c-48e3-879d-d97491e1bd3e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Timestamp</th>\n","      <th>Status</th>\n","      <th>Description</th>\n","      <th>Vibration Frequency</th>\n","      <th>Vibration Amplitude</th>\n","      <th>Bearing Temperature</th>\n","      <th>Motor Temperature</th>\n","      <th>Belt Load</th>\n","      <th>Torque</th>\n","      <th>Noise Levels</th>\n","      <th>Current and Voltage</th>\n","      <th>Hydraulic Pressure</th>\n","      <th>Belt Thickness</th>\n","      <th>Roller Condition</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Conveyor Belt 4</td>\n","      <td>2023-08-15 00:00:00</td>\n","      <td>Running</td>\n","      <td>NaN</td>\n","      <td>1490.82</td>\n","      <td>0.04</td>\n","      <td>NaN</td>\n","      <td>96.902</td>\n","      <td>1.36</td>\n","      <td>318.07</td>\n","      <td>55.12</td>\n","      <td>15.79</td>\n","      <td>382.09</td>\n","      <td>1.58</td>\n","      <td>86</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Conveyor Belt 4</td>\n","      <td>2023-08-15 00:15:00</td>\n","      <td>Running</td>\n","      <td>NaN</td>\n","      <td>1498.37</td>\n","      <td>0.04</td>\n","      <td>77.076</td>\n","      <td>96.975</td>\n","      <td>1.07</td>\n","      <td>295.5</td>\n","      <td>59.68</td>\n","      <td>14.34</td>\n","      <td>376.48</td>\n","      <td>1.5795</td>\n","      <td>85.854</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Conveyor Belt 4</td>\n","      <td>2023-08-15 00:30:00</td>\n","      <td>Running</td>\n","      <td>NaN</td>\n","      <td>1503.22</td>\n","      <td>0.06</td>\n","      <td>77.307</td>\n","      <td>96.755</td>\n","      <td>1.21</td>\n","      <td>314.38</td>\n","      <td>58.2</td>\n","      <td>15.03</td>\n","      <td>384.2</td>\n","      <td>1.57925</td>\n","      <td>85.781</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Conveyor Belt 4</td>\n","      <td>2023-08-15 00:45:00</td>\n","      <td>Running</td>\n","      <td>NaN</td>\n","      <td>1508.11</td>\n","      <td>0.04</td>\n","      <td>77.474</td>\n","      <td>97.661</td>\n","      <td>1.29</td>\n","      <td>311.84</td>\n","      <td>56.16</td>\n","      <td>15.43</td>\n","      <td>379.79</td>\n","      <td>1.579</td>\n","      <td>85.708</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Conveyor Belt 4</td>\n","      <td>2023-08-15 01:00:00</td>\n","      <td>Running</td>\n","      <td>NaN</td>\n","      <td>1498.13</td>\n","      <td>0.06</td>\n","      <td>77.785</td>\n","      <td>97.471</td>\n","      <td>1.07</td>\n","      <td>317.14</td>\n","      <td>55.39</td>\n","      <td>14.35</td>\n","      <td>383.95</td>\n","      <td>1.57875</td>\n","      <td>85.635</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Conveyor Belt 4</td>\n","      <td>2023-08-15 01:15:00</td>\n","      <td>Running</td>\n","      <td>NaN</td>\n","      <td>1494.89</td>\n","      <td>0.05</td>\n","      <td>77.813</td>\n","      <td>97.814</td>\n","      <td>1.33</td>\n","      <td>305.58</td>\n","      <td>NaN</td>\n","      <td>15.65</td>\n","      <td>383.02</td>\n","      <td>1.5785</td>\n","      <td>85.562</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Conveyor Belt 4</td>\n","      <td>2023-08-15 01:30:00</td>\n","      <td>Running</td>\n","      <td>NaN</td>\n","      <td>1498.2</td>\n","      <td>0.06</td>\n","      <td>77.622</td>\n","      <td>97.464</td>\n","      <td>1.18</td>\n","      <td>285.96</td>\n","      <td>59.25</td>\n","      <td>14.91</td>\n","      <td>383.54</td>\n","      <td>1.57825</td>\n","      <td>85.489</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Conveyor Belt 4</td>\n","      <td>2023-08-15 01:45:00</td>\n","      <td>Running</td>\n","      <td>NaN</td>\n","      <td>1507.17</td>\n","      <td>0.06</td>\n","      <td>78.487</td>\n","      <td>98.139</td>\n","      <td>1.24</td>\n","      <td>298.84</td>\n","      <td>58.93</td>\n","      <td>15.21</td>\n","      <td>377.37</td>\n","      <td>1.578</td>\n","      <td>85.416</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Conveyor Belt 4</td>\n","      <td>2023-08-15 02:00:00</td>\n","      <td>Running</td>\n","      <td>NaN</td>\n","      <td>1507.43</td>\n","      <td>0.06</td>\n","      <td>78.294</td>\n","      <td>97.877</td>\n","      <td>1.07</td>\n","      <td>307.51</td>\n","      <td>61.77</td>\n","      <td>14.36</td>\n","      <td>377.28</td>\n","      <td>1.57775</td>\n","      <td>85.343</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Conveyor Belt 4</td>\n","      <td>2023-08-15 02:15:00</td>\n","      <td>Running</td>\n","      <td>NaN</td>\n","      <td>1502.35</td>\n","      <td>0.05</td>\n","      <td>78.561</td>\n","      <td>98.96</td>\n","      <td>1.17</td>\n","      <td>308.73</td>\n","      <td>62.23</td>\n","      <td>14.87</td>\n","      <td>377.47</td>\n","      <td>1.5775</td>\n","      <td>85.27</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1180b0cb-955c-48e3-879d-d97491e1bd3e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1180b0cb-955c-48e3-879d-d97491e1bd3e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1180b0cb-955c-48e3-879d-d97491e1bd3e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9ac8f8a9-5cff-4f36-98f4-4d1b7666d937\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9ac8f8a9-5cff-4f36-98f4-4d1b7666d937')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9ac8f8a9-5cff-4f36-98f4-4d1b7666d937 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","repr_error":"Out of range float values are not JSON compliant: nan"}},"metadata":{}}],"source":["drive.mount('/content/drive')\n","\n","# Load Data Function\n","def load_data(file_path):\n","    \"\"\"Load data from an Excel file and display the first 10 rows.\"\"\"\n","    try:\n","        data = pd.read_excel(file_path, engine='openpyxl')\n","        print(\"Data loaded successfully.\")\n","        print(\"First 10 rows of the data:\")\n","        display(data.head(10))\n","        return data\n","    except FileNotFoundError:\n","        print(f\"Error: The file {file_path} was not found.\")\n","        return None\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","        return None\n","\n","file_path = '/content/drive/MyDrive/KSU/RCapstone/feature-prediction/data/all_data.xlsx'  # Update this to the correct path\n","data = load_data(file_path)"]},{"cell_type":"markdown","metadata":{"id":"817Pdx344cHj"},"source":["## 3. PreProcess Data\n","\n","We clean the data by converting everything into numbers, replacing missing values with zeros, and ensuring it's ready for the model."]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":267,"status":"ok","timestamp":1730086314012,"user":{"displayName":"l cn","userId":"00318376737157475686"},"user_tz":420},"id":"jUy47wuqcvX2"},"outputs":[],"source":["def preprocess_data(data):\n","    # Lag features\n","    for lag in range(1, 3):  # Simpler lag for testing\n","        data[f'Vibration Frequency lag {lag}'] = data['Vibration Frequency'].shift(lag)\n","\n","    # Drop NaNs\n","    data.dropna(inplace=True)\n","    return data\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6yVSXyyd4lpt"},"source":["## 4. Define Model\n","\n","This step creates a simple neural network with input, hidden, and output layers that will help the model learn and make predictions."]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":287,"status":"ok","timestamp":1730086265415,"user":{"displayName":"l cn","userId":"00318376737157475686"},"user_tz":420},"id":"9X_ISz98OiG9"},"outputs":[],"source":["# Create minimal sample data\n","data = pd.DataFrame({\n","    'Timestamp': pd.date_range(start='2023-01-01', periods=100, freq='D'),\n","    'Vibration Frequency': np.random.rand(100),\n","    'Vibration Amplitude': np.random.rand(100),\n","    'Bearing Temperature': np.random.rand(100) * 100\n","})\n","\n","data.set_index('Timestamp', inplace=True)\n","\n","\n","def build_model(input_shape):\n","    \"\"\"Build a simple neural network model.\"\"\"\n","    inputs = Input(shape=(input_shape,))\n","    x = Dense(128, activation='relu')(inputs)\n","    x = Dense(64, activation='relu')(x)\n","    outputs = Dense(1, activation='linear')(x)\n","    model = Model(inputs, outputs)\n","    model.compile(optimizer='adam', loss='mean_squared_error')\n","    return model"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"pYpS4xJb4tvx","executionInfo":{"status":"ok","timestamp":1730045871000,"user_tz":420,"elapsed":4,"user":{"displayName":"l cn","userId":"00318376737157475686"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"PlQT8P-we-6P"},"source":["## 5. Train Model\n","The data is scaled and split into training and test sets. We train the neural network for each target column, saving models and tools for future use, and stopping early if the model starts overfitting.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"8cIATHvzc7KW","executionInfo":{"status":"ok","timestamp":1730151688259,"user_tz":420,"elapsed":213,"user":{"displayName":"l cn","userId":"00318376737157475686"}}},"outputs":[],"source":["# Train Model Function\n","def train_model(data, target_column):\n","    # Preprocess the data\n","    print(f\"Preprocessing data for {target_column}...\")\n","    data = preprocess_data(data)\n","\n","    # Check the structure of the processed data\n","    print(\"Processed Data Columns:\", data.columns)\n","\n","    model_dir = '/content/drive/MyDrive/KSU/RCapstone/feature-prediction/models'\n","    if not os.path.exists(model_dir):\n","        os.makedirs(model_dir)\n","\n","    # Select all numeric columns for features\n","    numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()\n","    print(\"Numeric Columns Available for Features:\", numeric_columns)\n","\n","    # Ensure target_column exists in numeric columns\n","    if target_column not in numeric_columns:\n","        raise ValueError(f\"Target column '{target_column}' is not numeric or does not exist.\")\n","\n","    # Drop the target column from features\n","    X = data[numeric_columns].drop(columns=[target_column])\n","    y = data[target_column]  # Ensure target is numeric\n","\n","    # Print shapes of X and y before scaling\n","    print(f\"Shape of X: {X.shape}, Shape of y: {y.shape}\")\n","\n","    # Scale features\n","    scaler = MinMaxScaler()\n","    X_scaled = scaler.fit_transform(X)  # Scale only numeric features\n","\n","    # Train-test split (in time series, consider last n as test)\n","    split_index = int(len(X_scaled) * 0.8)  # 80% for training\n","    X_train, X_test = X_scaled[:split_index], X_scaled[split_index:]\n","    y_train, y_test = y[:split_index], y[split_index:]\n","\n","    # Print shapes of training and testing sets\n","    print(f\"Shape of X_train: {X_train.shape}, Shape of y_train: {y_train.shape}\")\n","\n","    model = build_model(X_train.shape[1])  # Input shape for the model\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","    # Train the model\n","    print(f\"Starting training for {target_column}...\")\n","    history = model.fit(X_train, y_train, epochs=100, batch_size=32,\n","                        validation_split=0.2, callbacks=[early_stopping], verbose=1)\n","\n","    print(f\"Training finished for {target_column}.\")\n","\n","    # Save the model and feature names\n","    model.save(f'{model_dir}/{target_column}_model.keras')\n","    joblib.dump(X.columns.tolist(), f'{model_dir}/{target_column}_feature_names.pkl')\n","\n","    return model, scaler, history  # Return history as well\n"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import joblib\n","import os\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import Input, Dense\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.callbacks import EarlyStopping\n","import matplotlib.pyplot as plt\n","from IPython.display import display\n","from google.colab import drive\n","\n","# Load the Drive\n","drive.mount('/content/drive')\n","\n","# Load Data Function\n","def load_data(file_path):\n","    \"\"\"Load data from an Excel file and display the first 10 rows.\"\"\"\n","    try:\n","        data = pd.read_excel(file_path, engine='openpyxl')\n","        print(\"Data loaded successfully.\")\n","        print(\"First 10 rows of the data:\")\n","        display(data.head(10))\n","        return data\n","    except FileNotFoundError:\n","        print(f\"Error: The file {file_path} was not found.\")\n","        return None\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")\n","        return None\n","\n","# Preprocess Data Function\n","def preprocess_data(data):\n","    \"\"\"Preprocess the data: handle numeric columns, create lagged features, and fill NaN values.\"\"\"\n","    # Convert Timestamp column to datetime\n","    data['Timestamp'] = pd.to_datetime(data['Timestamp'], errors='coerce')\n","\n","    # Check for any NaT values\n","    if data['Timestamp'].isna().any():\n","        print(\"Invalid datetime entries found in the Timestamp column:\")\n","        print(data[data['Timestamp'].isna()])  # Display rows with invalid datetime values\n","\n","    # Set Timestamp as index\n","    data.set_index('Timestamp', inplace=True)\n","\n","    # Create lagged features for 'Vibration Frequency' (can create for other features as needed)\n","    for lag in range(1, 5):\n","        data[f'Vibration Frequency lag {lag}'] = data['Vibration Frequency'].shift(lag)\n","\n","    # Convert all columns to numeric\n","    data = data.apply(pd.to_numeric, errors='coerce')\n","    data.fillna(0, inplace=True)\n","\n","    # Drop rows with NaN values created by shifting\n","    data.dropna(inplace=True)\n","\n","    return data\n","\n","# Build Model Function\n","def build_model(input_shape):\n","    \"\"\"Build a simple neural network model.\"\"\"\n","    inputs = Input(shape=(input_shape,))\n","    x = Dense(128, activation='relu')(inputs)\n","    x = Dense(64, activation='relu')(x)\n","    outputs = Dense(1, activation='linear')(x)\n","    model = Model(inputs, outputs)\n","    model.compile(optimizer='adam', loss='mean_squared_error')\n","    return model\n","\n","# Train Model Function\n","def train_model(data, target_column):\n","    # Preprocess the data\n","    data = preprocess_data(data)\n","\n","    # Check the structure of the processed data\n","    print(\"Processed Data Columns:\", data.columns)\n","\n","    model_dir = '/content/drive/MyDrive/KSU/RCapstone/feature-prediction/models'\n","    if not os.path.exists(model_dir):\n","        os.makedirs(model_dir)\n","\n","    # Select only numeric columns for X\n","    numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()\n","    print(\"Numeric Columns Available for Features:\", numeric_columns)\n","\n","    # Ensure target_column exists in numeric columns\n","    if target_column not in numeric_columns:\n","        raise ValueError(f\"Target column '{target_column}' is not numeric or does not exist.\")\n","\n","    # Drop the target column from features (do not drop Timestamp)\n","    X = data[numeric_columns].drop(columns=[target_column])\n","    y = data[target_column]  # Ensure target is numeric\n","\n","    # Scale features\n","    scaler = MinMaxScaler()\n","    X_scaled = scaler.fit_transform(X)  # Scale only numeric features\n","\n","    # Train-test split (in time series, consider last n as test)\n","    split_index = int(len(X_scaled) * 0.8)  # 80% for training\n","    X_train, X_test = X_scaled[:split_index], X_scaled[split_index:]\n","    y_train, y_test = y[:split_index], y[split_index:]\n","\n","    model = build_model(X_train.shape[1])  # Input shape for the model\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","\n","    # Train the model\n","    print(f\"Starting training for {target_column}...\")\n","    history = model.fit(X_train, y_train, epochs=100, batch_size=32,\n","                        validation_split=0.2, callbacks=[early_stopping], verbose=1)\n","\n","    print(f\"Training finished for {target_column}.\")\n","\n","    # Save the model and feature names\n","    model.save(f'{model_dir}/{target_column}_model.keras')\n","    joblib.dump(X.columns.tolist(), f'{model_dir}/{target_column}_feature_names.pkl')\n","\n","    return model, scaler, history\n","\n","# Function to Plot Training History\n","def plot_all_histories(histories):\n","    \"\"\"Plot the training and validation loss over epochs for each model after training.\"\"\"\n","    for target, history in histories.items():\n","        plt.figure(figsize=(12, 6))\n","        plt.plot(history.history['loss'], label='Training Loss')\n","        plt.plot(history.history['val_loss'], label='Validation Loss')\n","        plt.title(f'Training and Validation Loss for {target}')\n","        plt.xlabel('Epochs')\n","        plt.ylabel('Loss')\n","        plt.legend()\n","        plt.show()\n","\n","# Predict Last Rows Function\n","def predict_last_rows(models, data, scalers, target_columns):\n","    \"\"\"Predict the last 10 rows of the training data and compare predictions to actual values.\"\"\"\n","    last_n_rows = data.tail(10)\n","    results = []\n","\n","    for target in target_columns:\n","        # Load feature names\n","        feature_names = joblib.load(f'{model_dir}/{target}_feature_names.pkl')\n","\n","        # Prepare the last row features\n","        X_last = last_n_rows[feature_names].values\n","        X_last_scaled = scalers[target].transform(X_last)\n","\n","        # Make the prediction\n","        prediction = models[target].predict(X_last_scaled)\n","\n","        # Store predictions\n","        results.append((target, prediction))\n","\n","    # Create a DataFrame from results\n","    results_df = pd.DataFrame(results, columns=['Target', 'Prediction'])\n","    print(\"Predicted values for the last 10 rows:\")\n","    display(results_df)\n","\n","# Predict Next Rows Function\n","def predict_next_rows(models, data, scalers, target_columns, num_predictions=10):\n","    \"\"\"Predict the next num_predictions rows based on the trained data.\"\"\"\n","\n","    last_row = data.tail(1).copy()  # Use the last row to predict new values\n","    predicted_results = []\n","\n","    for target in target_columns:\n","        # Load feature names\n","        feature_names = joblib.load(f'{model_dir}/{target}_feature_names.pkl')\n","\n","        # Prepare for predictions\n","        for _ in range(num_predictions):\n","            # Select the last row features\n","            X_last = last_row[feature_names].values\n","            X_last_scaled = scalers[target].transform(X_last)\n","\n","            # Make the prediction\n","            prediction = models[target].predict(X_last_scaled)\n","\n","            # Store the predicted value\n","            predicted_results.append((target, prediction[0][0]))\n","\n","            # Update the last_row for the next prediction\n","            last_row = pd.DataFrame([last_row.values.flatten().tolist() + [prediction[0][0]]], columns=last_row.columns)\n","            last_row.index = [pd.to_datetime(last_row.index[0]) + pd.Timedelta(minutes=5)]  # Increment timestamp\n","\n","    # Create a DataFrame from the predictions\n","    predicted_df = pd.DataFrame(predicted_results, columns=['Target', 'Prediction'])\n","    print(f\"Predicted next {num_predictions} rows based on the trained data:\")\n","    display(predicted_df)\n","\n","# Train models for all target columns\n","target_columns = [\n","    'Vibration Frequency',\n","    'Vibration Amplitude',\n","    'Bearing Temperature',\n","    'Motor Temperature',\n","    'Belt Load',\n","    'Torque',\n","    'Noise Levels',\n","    'Current and Voltage',\n","    'Hydraulic Pressure',\n","    'Belt Thickness',\n","    'Roller Condition'\n","]\n","\n","models = {}\n","scalers = {}\n","histories = {}  # Initialize the histories dictionary\n","\n","# Track any errors during training\n","for target in target_columns:\n","    print(f\"Training model for {target}...\")\n","    try:\n","        model, scaler, history = train_model(data, target)\n","        models[target] = model\n","        scalers[target] = scaler\n","        histories[target] = history  # Store the history for each model\n","\n","    except KeyError as e:\n","        print(f\"KeyError: {e} - likely due to accessing a dropped column or index.\")\n","    except Exception as e:\n","        print(f\"Error while training model for {target}: {e}\")\n","\n","# Plot all training histories after all models have been trained\n","plot_all_histories(histories)\n","\n","# Predicting the last 10\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UIK1MKBJMOeR","executionInfo":{"status":"ok","timestamp":1730086624214,"user_tz":420,"elapsed":1534,"user":{"displayName":"l cn","userId":"00318376737157475686"}},"outputId":"bdd5156d-7d32-4faf-bc5a-440ca1a59c7d"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Training model for Vibration Frequency...\n","KeyError: 'Timestamp' - likely due to accessing a dropped column or index.\n","Training model for Vibration Amplitude...\n","KeyError: 'Timestamp' - likely due to accessing a dropped column or index.\n","Training model for Bearing Temperature...\n","KeyError: 'Timestamp' - likely due to accessing a dropped column or index.\n","Training model for Motor Temperature...\n","KeyError: 'Timestamp' - likely due to accessing a dropped column or index.\n","Training model for Belt Load...\n","KeyError: 'Timestamp' - likely due to accessing a dropped column or index.\n","Training model for Torque...\n","KeyError: 'Timestamp' - likely due to accessing a dropped column or index.\n","Training model for Noise Levels...\n","KeyError: 'Timestamp' - likely due to accessing a dropped column or index.\n","Training model for Current and Voltage...\n","KeyError: 'Timestamp' - likely due to accessing a dropped column or index.\n","Training model for Hydraulic Pressure...\n","KeyError: 'Timestamp' - likely due to accessing a dropped column or index.\n","Training model for Belt Thickness...\n","KeyError: 'Timestamp' - likely due to accessing a dropped column or index.\n","Training model for Roller Condition...\n","KeyError: 'Timestamp' - likely due to accessing a dropped column or index.\n"]}]},{"cell_type":"markdown","metadata":{"id":"pNNGTjo44ywY"},"source":["# 6. Display Training History\n","\n","This step shows the loss (errors) during training and validation to help us understand how well the model is learning."]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":218,"status":"ok","timestamp":1730086335233,"user":{"displayName":"l cn","userId":"00318376737157475686"},"user_tz":420},"id":"YRdcyb56dwq7"},"outputs":[],"source":["def plot_history(history, target):\n","    \"\"\"Plot the training and validation loss over epochs for each model.\"\"\"\n","    plt.figure(figsize=(12, 6))\n","    plt.plot(history.history['loss'], label='Training Loss')\n","    plt.plot(history.history['val_loss'], label='Validation Loss')\n","    plt.title(f'Training and Validation Loss for {target}')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","for target, history in histories.items():\n","    plot_history(history, target)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"cjxhwoF-HirP","executionInfo":{"status":"ok","timestamp":1730085723056,"user_tz":420,"elapsed":249,"user":{"displayName":"l cn","userId":"00318376737157475686"}}},"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UKR4_twG47zM"},"source":["# 7.Evaluate Model\n","\n","The model predicts the last 10 rows of training data, compares predictions to actual values, and uses colors to highlight how close the predictions are to the real values."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":180},"executionInfo":{"elapsed":427,"status":"error","timestamp":1730045986010,"user":{"displayName":"l cn","userId":"00318376737157475686"},"user_tz":420},"id":"VjOoHuIbq3Bf","outputId":"fbac7a25-a900-461e-9a95-965c42d7db88"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'models' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-7c53d8bf2c4a>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Use the function to evaluate the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mpredict_last_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessed_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"]}],"source":["# 7. Evaluate Model\n","def predict_last_rows(models, data, scalers, target_columns):\n","    \"\"\"Predict the last 10 rows of the training data and compare predictions to actual values.\"\"\"\n","    last_n_rows = data.tail(10)\n","    results = []\n","    model_dir = '/content/drive/MyDrive/KSU/RCapstone/feature-prediction/models'\n","\n","    for i in range(len(last_n_rows)):\n","        original_row = {'Type': 'Original'}\n","        predicted_row = {'Type': 'Predicted'}\n","\n","        for target in target_columns:\n","            feature_names = joblib.load(f'{model_dir}/{target}_feature_names.pkl')\n","            X_last = last_n_rows[feature_names].iloc[[i]]\n","            X_last_scaled = scalers[target].transform(X_last)\n","            prediction = models[target].predict(X_last_scaled)\n","\n","            original_row[target] = last_n_rows.iloc[i][target]\n","            predicted_row[target] = prediction[0]\n","\n","        results.append(original_row)\n","        results.append(predicted_row)\n","\n","    results_df = pd.DataFrame(results)\n","    display(results_df)\n","\n","# Use the function to evaluate the predictions\n","predict_last_rows(models, processed_data, scalers, target_columns)\n"]},{"cell_type":"markdown","metadata":{"id":"Iio0JgzW5CM4"},"source":["## 8. Predict Next 10 rows\n","\n","Based on the last row of data, the model predicts the next 10 rows for each column and displays the predicted results."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"aborted","timestamp":1730045872259,"user":{"displayName":"l cn","userId":"00318376737157475686"},"user_tz":420},"id":"4_gAGKX1sAO6"},"outputs":[],"source":["def predict_next_rows_from_training(models, data, scalers, target_columns, num_predictions=10):\n","    \"\"\"Predict the next num_predictions rows based on the trained data, using previous predictions.\"\"\"\n","\n","    # Convert the timestamp column to datetime if it's still in string format\n","    if data.index.dtype == 'object':  # Check if index is still string\n","        data.index = pd.to_datetime(data.index)\n","\n","    # Use the last row to predict new values\n","    last_row = data.tail(1).copy()  # Get the last row for predictions\n","    model_dir = '/content/drive/MyDrive/KSU/RCapstone/feature-prediction/models'\n","    predicted_results = []  # To store the results\n","\n","    # Predict for the specified number of future time steps\n","    for i in range(num_predictions):\n","        predicted_row = {}\n","\n","        for target in target_columns:\n","            feature_names = joblib.load(f'{model_dir}/{target}_feature_names.pkl')\n","            X_last = last_row[feature_names]\n","\n","            # Scale the features\n","            X_last_scaled = scalers[target].transform(X_last)\n","\n","            # Make the prediction\n","            prediction = models[target].predict(X_last_scaled)\n","\n","            # Extract the predicted value\n","            predicted_value = prediction[0].item() if isinstance(prediction[0], (list, np.ndarray)) else prediction[0]\n","            predicted_row[target] = predicted_value\n","\n","            # Update the last_row for the next prediction\n","            last_row[target] = predicted_value  # This will help to maintain continuity\n","\n","        # Create a new timestamp for each prediction\n","        new_timestamp = last_row.index[0] + pd.Timedelta(minutes=5)  # Ensure index is accessed correctly\n","        predicted_row['timestamp'] = new_timestamp\n","\n","        # Append predicted_row to results\n","        predicted_results.append(predicted_row)\n","\n","        # Update the last_row to include the new prediction for the next iteration\n","        last_row = pd.DataFrame([predicted_row]).set_index('timestamp')\n","\n","    # Create a DataFrame from the predicted results\n","    predicted_df = pd.DataFrame(predicted_results)\n","    predicted_df.set_index('timestamp', inplace=True)\n","\n","    print(f\"Predicted next {num_predictions} rows based on the trained data:\")\n","    display(predicted_df)  # Use display to show the DataFrame\n","\n","    return predicted_df\n","\n","# Call the function to get predicted results for the next rows\n","predicted_next_df = predict_next_rows_from_training(models, processed_data, scalers, target_columns, num_predictions=10)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l4ZAX-UJ5Alp","executionInfo":{"status":"aborted","timestamp":1730045872259,"user_tz":420,"elapsed":3,"user":{"displayName":"l cn","userId":"00318376737157475686"}}},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMiKy0vJ8vn5aeAmuIrtkuh"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}